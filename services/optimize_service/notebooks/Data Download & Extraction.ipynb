{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b44cc80",
   "metadata": {},
   "source": [
    "# Kaggle Dataset Download & Hector CSV Conversion\n",
    "\n",
    "## Purpose\n",
    "This notebook handles:\n",
    "1. **Kaggle dataset acquisition** - Downloads weather and climate datasets from Kaggle\n",
    "2. **Hector dataset conversion** - Converts Excel to CSV format (weather/climate data only, excluding rice)\n",
    "\n",
    "## What This Notebook Does\n",
    "1. Downloads 2 Kaggle datasets (weather and climate data)\n",
    "2. Extracts and organizes CSV files\n",
    "3. Converts Hector Excel dataset to CSV format (wide and long formats) - **Excludes rice-related items**\n",
    "4. Creates organized directory structure for data storage\n",
    "\n",
    "## When to Run\n",
    "- **First time setup**: Run once before the main analysis notebook\n",
    "- **Data updates**: Re-run to download updated versions\n",
    "- **Hector conversion**: Run when new Excel file is added\n",
    "\n",
    "## Requirements\n",
    "- **Kaggle API credentials**: `kaggle.json` in `~/.kaggle/` directory\n",
    "  - Download from: https://www.kaggle.com/settings (Account → API → Create New Token)\n",
    "  - Windows: `C:\\Users\\<username>\\.kaggle\\kaggle.json`\n",
    "  - Linux/Mac: `~/.kaggle/kaggle.json`\n",
    "- **Hector Excel file**: Place in `data/Hector/Retail Prices 2015-2024.xlsx`\n",
    "\n",
    "## Output\n",
    "- `data/kaggle/` - Weather and climate CSV datasets\n",
    "- `data/Hector/retail_prices_wide.csv` - Hector data in wide format (no rice items)\n",
    "- `data/Hector/retail_prices_long.csv` - Hector data in long format (no rice items, recommended for ML)\n",
    "\n",
    "## Hector Dataset Info\n",
    "- **Coverage**: 2015-2024 (9 years)\n",
    "- **Items**: Weather and climate related commodities (rice items excluded)\n",
    "- **Locations**: 37 locations across Sri Lanka\n",
    "- **Format**: Weekly prices for vegetables, fruits, etc. (excluding rice varieties)\n",
    "\n",
    "## Next Step\n",
    "After completion, run: **`Adaptive Crop & Area Optimization.ipynb`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b23812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: black>=24.10.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (25.11.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: kagglesdk in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (0.1.13)\n",
      "Requirement already satisfied: mypy>=1.15.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (1.18.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (6.33.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (65.5.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: types-requests in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.32.4.20250913)\n",
      "Requirement already satisfied: types-tqdm in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (4.67.0.20250809)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=24.10.0->kaggle) (8.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=24.10.0->kaggle) (1.1.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=24.10.0->kaggle) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=24.10.0->kaggle) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\dilan\\appdata\\roaming\\python\\python311\\site-packages (from black>=24.10.0->kaggle) (4.4.0)\n",
      "Requirement already satisfied: pytokens>=0.3.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=24.10.0->kaggle) (0.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.6.0 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mypy>=1.15.0->kaggle) (4.15.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kaggle) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kaggle) (2025.11.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\dilan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "\n",
      "Dependencies installed!\n",
      "\n",
      "Next: Ensure kaggle.json is in ~/.kaggle/ directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INSTALL REQUIRED DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "!pip install kaggle pandas numpy\n",
    "\n",
    "print(\"\\nDependencies installed!\")\n",
    "print(\"\\nNext: Ensure kaggle.json is in ~/.kaggle/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7731293",
   "metadata": {},
   "source": [
    "## 2. Kaggle Dataset Download\n",
    "\n",
    "Downloads weather and climate datasets from Kaggle for Sri Lanka.\n",
    "\n",
    "**Datasets:**\n",
    "1. Weather Data\n",
    "2. Climate Data (314K+ records)\n",
    "\n",
    "**Vegetable Prices:**\n",
    "Vegetable price data is available in the local Hector dataset at `data/Hector/Retail Prices 2015-2024.xlsx` (rice items will be excluded during processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f47d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created/verified: data/kaggle\n",
      "Created/verified: ../app/models\n",
      "\n",
      "Directory structure ready!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP DIRECTORIES\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "directories = [\"data/kaggle\", \"../app/models\"]\n",
    "\n",
    "for dir_path in directories:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"Created/verified: {dir_path}\")\n",
    "\n",
    "print(\"\\nDirectory structure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6372dbf",
   "metadata": {},
   "source": [
    "### 2.2 Kaggle Dataset Configuration\n",
    "\n",
    "**2 Kaggle Datasets (Sri Lanka Weather & Climate Data):**\n",
    "\n",
    "| # | Dataset | Description |\n",
    "|---|---------|-------------|\n",
    "| 1 | weather_sl | Sri Lanka weather dataset |\n",
    "| 2 | climate_data_sl | Sri Lanka climate data (314K+ records) |\n",
    "\n",
    "**Note:** Vegetable price data is available in the local Hector dataset (data/Hector/Retail Prices 2015-2024.xlsx) which covers 2015-2024. Rice-related items will be excluded during processing to focus on weather and climate-relevant commodities only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212346b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded: 2 datasets (weather & climate only)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# KAGGLE DATASET CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "KAGGLE_DATASETS = {\n",
    "    # Climate & Weather ONLY\n",
    "    \"weather_sl\":               \"rasulmah/sri-lanka-weather-dataset\",\n",
    "    \"climate_data_sl\":          \"tharindumadhusanka9/sri-lanka-climate-data\",\n",
    "}\n",
    "\n",
    "# Note: All rice-related and economy datasets have been removed\n",
    "# This notebook now focuses exclusively on weather and climate data\n",
    "# Hector dataset processing will exclude rice items to maintain weather/climate focus\n",
    "\n",
    "print(f\"Configuration loaded: {len(KAGGLE_DATASETS)} datasets (weather & climate only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61e0621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download function defined\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# KAGGLE DOWNLOAD FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "def download_kaggle_datasets():\n",
    "    \"\"\"\n",
    "    Download all Kaggle datasets using Kaggle API.\n",
    "    Skips datasets that already exist.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DOWNLOADING KAGGLE DATASETS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    KAGGLE_DIR = Path(\"data/kaggle\")\n",
    "    \n",
    "    for nickname, slug in KAGGLE_DATASETS.items():\n",
    "        target = KAGGLE_DIR / nickname\n",
    "        target.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Skip if already downloaded\n",
    "        if list(target.glob('*.csv')):\n",
    "            print(f\"[SKIP] {nickname:30s} | Already exists\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"[DOWN] {nickname:30s} | Downloading...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [\"kaggle\", \"datasets\", \"download\", \"-d\", slug, \"-p\", str(target), \"--unzip\"],\n",
    "                check=True,\n",
    "                capture_output=True\n",
    "            )\n",
    "            print(f\"[OK]   {nickname:30s} | Downloaded successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"[ERR]  {nickname:30s} | Error: {e}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[ERR]  Kaggle CLI not found. Install with: pip install kaggle\")\n",
    "            break\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nKaggle download complete!\")\n",
    "\n",
    "print(\"Download function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd005b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                    KAGGLE DOWNLOAD PIPELINE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "DOWNLOADING KAGGLE DATASETS\n",
      "======================================================================\n",
      "[DOWN] weather_sl                     | Downloading...\n",
      "[OK]   weather_sl                     | Downloaded successfully\n",
      "[DOWN] climate_data_sl                | Downloading...\n",
      "[OK]   climate_data_sl                | Downloaded successfully\n",
      "======================================================================\n",
      "\n",
      "Kaggle download complete!\n",
      "\n",
      "======================================================================\n",
      "                         COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "All datasets downloaded!\n",
      "Location: data/kaggle/\n",
      "Next: Run 'Adaptive Crop & Area Optimization.ipynb'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXECUTE KAGGLE DOWNLOAD\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"KAGGLE DOWNLOAD PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "download_kaggle_datasets()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*25 + \"COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAll datasets downloaded!\")\n",
    "print(\"Location: data/kaggle/\")\n",
    "print(\"Next: Run 'Adaptive Crop & Area Optimization.ipynb'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c482885",
   "metadata": {},
   "source": [
    "## 3. Download Summary\n",
    "\n",
    "### Downloaded Datasets (2 total)\n",
    "\n",
    "1. **Weather** - Sri Lanka weather dataset\n",
    "2. **Climate** - 314K+ climate records\n",
    "\n",
    "### Local Dataset (Already Available)\n",
    "\n",
    "**Hector Dataset** - `data/Hector/Retail Prices 2015-2024.xlsx`\n",
    "- Food commodities (excluding rice items)\n",
    "- 37 locations across Sri Lanka\n",
    "- Weekly average retail prices (2015-2024)\n",
    "- Items include: Tomatoes, Carrot, Beans, Leeks, and other vegetables/fruits (no rice)\n",
    "\n",
    "### Directory Structure\n",
    "```\n",
    "data/\n",
    "├── kaggle/                    # Downloaded Kaggle datasets\n",
    "│   ├── weather_sl/\n",
    "│   └── climate_data_sl/\n",
    "└── Hector/                    # Local Hector dataset (provided)\n",
    "    └── Retail Prices 2015-2024.xlsx\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Verify downloads**: Run verification cell below\n",
    "2. **Run main notebook**: Open `Adaptive Crop & Area Optimization.ipynb`\n",
    "3. **Model training**: Main notebook will load weather, climate, and Hector datasets (excluding rice)\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**Kaggle API errors:**\n",
    "- Check `kaggle.json` location:\n",
    "  - Windows: `C:\\Users\\<username>\\.kaggle\\kaggle.json`\n",
    "  - Linux/Mac: `~/.kaggle/kaggle.json`\n",
    "- Verify credentials: Run `kaggle datasets list` in terminal\n",
    "- Accept dataset terms on Kaggle website\n",
    "\n",
    "**Re-downloading:**\n",
    "- Delete specific dataset folder to re-download\n",
    "- Smart skip prevents duplicate downloads\n",
    "\n",
    "**Disk space:**\n",
    "- Expected: ~65-70 MB (2 Kaggle datasets: weather & climate)\n",
    "\n",
    "**Rice data exclusion:**\n",
    "- All rice-related items are automatically filtered out during Hector dataset conversion\n",
    "- This includes varieties like Samba, Nadu, Keeri, Kekulu, Basmati, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfaaeb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                      VERIFICATION REPORT\n",
      "======================================================================\n",
      "\n",
      "[OK]  weather_sl                     |   2 files |  42.21 MB\n",
      "[OK]  climate_data_sl                |   1 files |  23.79 MB\n",
      "\n",
      "======================================================================\n",
      "TOTAL: 3 files | 66.00 MB\n",
      "======================================================================\n",
      "\n",
      "All datasets downloaded successfully!\n",
      "Ready for: Adaptive Crop & Area Optimization.ipynb\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFY DOWNLOADS\n",
    "# =============================================================================\n",
    "\n",
    "def verify_downloads():\n",
    "    \"\"\"Verify all datasets were downloaded.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\" \"*22 + \"VERIFICATION REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "    \n",
    "    datasets = list(KAGGLE_DATASETS.keys())\n",
    "    missing = []\n",
    "    total_files = 0\n",
    "    total_size = 0\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        path = f\"data/kaggle/{dataset}\"\n",
    "        if os.path.exists(path) and os.listdir(path):\n",
    "            file_count = len(os.listdir(path))\n",
    "            size = sum(os.path.getsize(os.path.join(path, f)) \n",
    "                      for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)))\n",
    "            size_mb = size / (1024 * 1024)\n",
    "            print(f\"[OK]  {dataset:30s} | {file_count:3d} files | {size_mb:6.2f} MB\")\n",
    "            total_files += file_count\n",
    "            total_size += size_mb\n",
    "        else:\n",
    "            print(f\"[MISS] {dataset:30s} | NOT FOUND\")\n",
    "            missing.append(dataset)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*70)\n",
    "    print(f\"TOTAL: {total_files} files | {total_size:.2f} MB\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not missing:\n",
    "        print(\"\\nAll datasets downloaded successfully!\")\n",
    "        print(\"Ready for: Adaptive Crop & Area Optimization.ipynb\")\n",
    "    else:\n",
    "        print(f\"\\n{len(missing)} dataset(s) missing:\")\n",
    "        for ds in missing:\n",
    "            print(f\"   - {ds}\")\n",
    "        print(\"\\nTip: Re-run download cell above\")\n",
    "\n",
    "verify_downloads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qs13ledbx9",
   "metadata": {},
   "source": [
    "## 4. Hector Dataset CSV Conversion\n",
    "\n",
    "The Hector dataset is provided as an Excel file. This section converts it to CSV format for easier processing in analysis and ML models.\n",
    "\n",
    "**Important**: Rice-related items are excluded from the conversion to focus on weather and climate-relevant commodities only.\n",
    "\n",
    "**Input**: `data/Hector/Retail Prices 2015-2024.xlsx`\n",
    "\n",
    "**Output**:\n",
    "- `retail_prices_wide.csv` - Same structure as Excel (excluding rice items)\n",
    "- `retail_prices_long.csv` - Time series format (excluding rice items, recommended for ML)\n",
    "\n",
    "**Rice items excluded**: All items containing keywords like \"Rice\", \"Samba\", \"Nadu\", \"Keeri\", \"Kekulu\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59r65bhley3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HECTOR DATASET CONVERSION: Excel to CSV (Excluding Rice Items)\n",
      "======================================================================\n",
      "\n",
      "[SKIP] CSV files already exist\n",
      "       data/Hector\\retail_prices_wide.csv\n",
      "       data/Hector\\retail_prices_long.csv\n",
      "\n",
      "       Delete CSV files to regenerate\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONVERT HECTOR EXCEL TO CSV (EXCLUDING RICE ITEMS)\n",
    "# =============================================================================\n",
    "\n",
    "INPUT_FILE = \"data/Hector/Retail Prices 2015-2024.xlsx\"\n",
    "OUTPUT_DIR = \"data/Hector\"\n",
    "OUTPUT_WIDE = os.path.join(OUTPUT_DIR, \"retail_prices_wide.csv\")\n",
    "OUTPUT_LONG = os.path.join(OUTPUT_DIR, \"retail_prices_long.csv\")\n",
    "\n",
    "# Rice-related keywords to exclude\n",
    "RICE_KEYWORDS = [\n",
    "    'rice', 'samba', 'nadu', 'keeri', 'kekulu', 'rathu', 'kalu',\n",
    "    'basmati', 'red rice', 'white rice', 'parboiled', 'raw rice'\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HECTOR DATASET CONVERSION: Excel to CSV (Excluding Rice Items)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if Excel file exists\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    print(f\"\\n[SKIP] Excel file not found: {INPUT_FILE}\")\n",
    "    print(\"       Place the Excel file in data/Hector/ directory\")\n",
    "else:\n",
    "    # Check if CSV files already exist\n",
    "    if os.path.exists(OUTPUT_WIDE) and os.path.exists(OUTPUT_LONG):\n",
    "        print(f\"\\n[SKIP] CSV files already exist\")\n",
    "        print(f\"       {OUTPUT_WIDE}\")\n",
    "        print(f\"       {OUTPUT_LONG}\")\n",
    "        print(\"\\n       Delete CSV files to regenerate\")\n",
    "    else:\n",
    "        # Install openpyxl if needed\n",
    "        try:\n",
    "            import openpyxl\n",
    "        except ImportError:\n",
    "            print(\"\\n[1/6] Installing openpyxl for Excel support...\")\n",
    "            import subprocess\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"openpyxl\"])\n",
    "            import openpyxl\n",
    "        \n",
    "        # Read Excel file\n",
    "        print(f\"\\n[1/6] Reading Excel file: {INPUT_FILE}\")\n",
    "        df = pd.read_excel(INPUT_FILE, sheet_name='2015-2024', header=2)\n",
    "        print(f\"      Loaded {len(df):,} records\")\n",
    "        \n",
    "        # Filter out rice items\n",
    "        print(f\"\\n[2/6] Filtering out rice-related items...\")\n",
    "        original_count = len(df)\n",
    "        \n",
    "        # Create a mask to exclude rows where 'Items' contains any rice keyword\n",
    "        rice_mask = df['Items'].str.lower().str.contains('|'.join(RICE_KEYWORDS), case=False, na=False)\n",
    "        df = df[~rice_mask]\n",
    "        \n",
    "        removed_count = original_count - len(df)\n",
    "        print(f\"      Removed {removed_count:,} rice-related records\")\n",
    "        print(f\"      Remaining {len(df):,} records (weather/climate relevant)\")\n",
    "        \n",
    "        if removed_count > 0:\n",
    "            print(f\"      Unique rice items removed: {df[rice_mask]['Items'].nunique() if original_count > len(df) else 0}\")\n",
    "        \n",
    "        # Save wide format\n",
    "        print(f\"\\n[3/6] Saving wide format CSV: {OUTPUT_WIDE}\")\n",
    "        df.to_csv(OUTPUT_WIDE, index=False, encoding='utf-8')\n",
    "        file_size = os.path.getsize(OUTPUT_WIDE) / (1024 * 1024)\n",
    "        print(f\"      Saved: {file_size:.2f} MB\")\n",
    "        \n",
    "        # Convert to long format\n",
    "        print(f\"\\n[4/6] Converting to long format...\")\n",
    "        weekly_cols = [col for col in df.columns if col.startswith('W') and col[1:].isdigit()]\n",
    "        \n",
    "        df_long = df.melt(\n",
    "            id_vars=['Year', 'Loc Cod', 'Location', 'Item Cod', 'Items'],\n",
    "            value_vars=weekly_cols,\n",
    "            var_name='Week',\n",
    "            value_name='Price'\n",
    "        )\n",
    "        \n",
    "        # Extract week number\n",
    "        df_long['Week_Num'] = df_long['Week'].str.extract('(\\d+)').astype(int)\n",
    "        \n",
    "        # Filter out rows with non-numeric years\n",
    "        df_long = df_long[pd.to_numeric(df_long['Year'], errors='coerce').notna()]\n",
    "        df_long['Year'] = df_long['Year'].astype(int)\n",
    "        \n",
    "        # Create date column\n",
    "        df_long['Date'] = pd.to_datetime(df_long['Year'].astype(str) + '-01-01') + pd.to_timedelta((df_long['Week_Num'] - 1) * 7, unit='D')\n",
    "        \n",
    "        # Reorder columns\n",
    "        df_long = df_long[['Year', 'Week_Num', 'Week', 'Date', 'Loc Cod', 'Location', 'Item Cod', 'Items', 'Price']]\n",
    "        \n",
    "        # Sort and remove missing prices\n",
    "        df_long = df_long.sort_values(['Year', 'Week_Num', 'Location', 'Items'])\n",
    "        df_long = df_long.dropna(subset=['Price'])\n",
    "        \n",
    "        # Save long format\n",
    "        print(f\"\\n[5/6] Saving long format CSV: {OUTPUT_LONG}\")\n",
    "        df_long.to_csv(OUTPUT_LONG, index=False, encoding='utf-8')\n",
    "        file_size = os.path.getsize(OUTPUT_LONG) / (1024 * 1024)\n",
    "        print(f\"      Saved: {file_size:.2f} MB\")\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n[6/6] Processing complete\")\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CONVERSION COMPLETE (Rice Items Excluded)\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nWide Format: {len(df):,} records\")\n",
    "        print(f\"Long Format: {len(df_long):,} records\")\n",
    "        print(f\"Years: {df_long['Year'].min()}-{df_long['Year'].max()}\")\n",
    "        print(f\"Items: {df_long['Items'].nunique()} (no rice varieties)\")\n",
    "        print(f\"Locations: {df_long['Location'].nunique()}\")\n",
    "        print(f\"\\nNote: All rice-related items have been excluded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
