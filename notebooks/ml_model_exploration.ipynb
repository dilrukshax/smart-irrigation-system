{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdd90c3",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Basic imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print(\"Scikit-learn imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Libraries (PyTorch)\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed. Install with: pip install torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a94bb",
   "metadata": {},
   "source": [
    "## 2. F3 - Time Series Forecasting Models\n",
    "\n",
    "The forecasting service uses ML models to predict:\n",
    "- Water levels (1-72 hours ahead)\n",
    "- Rainfall patterns\n",
    "- Flood/drought risk assessment\n",
    "\n",
    "### 2.1 Understanding the Current Forecasting System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61238bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate historical data similar to the forecasting service\n",
    "import time\n",
    "import random\n",
    "\n",
    "def generate_water_level_data(days=30, hourly=True):\n",
    "    \"\"\"Generate simulated water level data with seasonal patterns.\"\"\"\n",
    "    periods = days * 24 if hourly else days\n",
    "    base_time = datetime.now() - timedelta(days=days)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(periods):\n",
    "        if hourly:\n",
    "            timestamp = base_time + timedelta(hours=i)\n",
    "        else:\n",
    "            timestamp = base_time + timedelta(days=i)\n",
    "        \n",
    "        # Seasonal pattern\n",
    "        day_of_year = timestamp.timetuple().tm_yday\n",
    "        seasonal_factor = 0.5 + 0.5 * np.sin(2 * np.pi * day_of_year / 365)\n",
    "        \n",
    "        # Water level (0-100% of capacity)\n",
    "        base_level = 60 + 20 * seasonal_factor\n",
    "        water_level = max(10, min(95, base_level + random.uniform(-10, 10)))\n",
    "        \n",
    "        # Rainfall (mm per hour/day)\n",
    "        rainfall_prob = 0.3 if seasonal_factor > 0.6 else 0.1\n",
    "        rainfall = random.uniform(0, 15) if random.random() < rainfall_prob else 0\n",
    "        \n",
    "        # Dam gate opening\n",
    "        gate_opening = min(80, max(0, water_level - 50 + random.uniform(-10, 10)))\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'water_level_percent': round(water_level, 2),\n",
    "            'rainfall_mm': round(rainfall, 2),\n",
    "            'gate_opening_percent': round(gate_opening, 2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate sample data\n",
    "df_water = generate_water_level_data(days=60)\n",
    "print(f\"Generated {len(df_water)} hours of water level data\")\n",
    "df_water.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the water level data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Water Level\n",
    "axes[0].plot(df_water['timestamp'], df_water['water_level_percent'], 'b-', alpha=0.7)\n",
    "axes[0].set_ylabel('Water Level (%)')\n",
    "axes[0].set_title('Water Level Over Time')\n",
    "axes[0].axhline(y=85, color='r', linestyle='--', label='Flood Warning')\n",
    "axes[0].axhline(y=20, color='orange', linestyle='--', label='Drought Warning')\n",
    "axes[0].legend()\n",
    "\n",
    "# Rainfall\n",
    "axes[1].bar(df_water['timestamp'], df_water['rainfall_mm'], color='cyan', alpha=0.7)\n",
    "axes[1].set_ylabel('Rainfall (mm)')\n",
    "axes[1].set_title('Rainfall Over Time')\n",
    "\n",
    "# Gate Opening\n",
    "axes[2].plot(df_water['timestamp'], df_water['gate_opening_percent'], 'g-', alpha=0.7)\n",
    "axes[2].set_ylabel('Gate Opening (%)')\n",
    "axes[2].set_title('Dam Gate Opening Over Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c4ace",
   "metadata": {},
   "source": [
    "### 2.2 LSTM Model for Water Level Forecasting\n",
    "\n",
    "Long Short-Term Memory (LSTM) networks are ideal for time series forecasting because they can:\n",
    "- Remember long-term dependencies\n",
    "- Handle sequential data with varying time lags\n",
    "- Learn complex temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0496af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM Model Architecture\n",
    "class WaterLevelLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM-based model for water level forecasting.\n",
    "    \n",
    "    Architecture:\n",
    "    - Input: Sequence of [water_level, rainfall, gate_opening]\n",
    "    - LSTM layers with dropout for regularization\n",
    "    - Fully connected output layer\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=3, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super(WaterLevelLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the last output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Print model architecture\n",
    "model = WaterLevelLSTM()\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad228f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM training\n",
    "def create_sequences(data, seq_length=24):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with features\n",
    "        seq_length: Number of time steps to look back\n",
    "    \n",
    "    Returns:\n",
    "        X: Input sequences (batch, seq_length, features)\n",
    "        y: Target values (batch, 1)\n",
    "    \"\"\"\n",
    "    features = ['water_level_percent', 'rainfall_mm', 'gate_opening_percent']\n",
    "    target = 'water_level_percent'\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data[features])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-seq_length:i])\n",
    "        y.append(scaled_data[i, 0])  # Water level is first feature\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "# Create sequences\n",
    "SEQ_LENGTH = 24  # Use 24 hours of history\n",
    "X, y, scaler = create_sequences(df_water, SEQ_LENGTH)\n",
    "\n",
    "print(f\"Input shape: {X.shape} (samples, sequence_length, features)\")\n",
    "print(f\"Output shape: {y.shape} (samples,)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e104433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, X_test, y_test, epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train the LSTM model.\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_test)\n",
    "            val_loss = criterion(val_outputs, y_test).item()\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Train the model\n",
    "model = WaterLevelLSTM(input_size=3, hidden_size=64, num_layers=2)\n",
    "train_losses, val_losses = train_model(model, train_loader, X_test_tensor, y_test_tensor, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d373661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(train_losses, label='Training Loss')\n",
    "axes[0].plot(val_losses, label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Predictions vs Actual\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).numpy()\n",
    "\n",
    "axes[1].plot(y_test[:100], label='Actual', alpha=0.7)\n",
    "axes[1].plot(predictions[:100], label='Predicted', alpha=0.7)\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Water Level (Normalized)')\n",
    "axes[1].set_title('Predictions vs Actual (First 100 samples)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1d6d",
   "metadata": {},
   "source": [
    "## 3. F4 - ACA-O Optimization Models\n",
    "\n",
    "The ACA-O (Adaptive Crop & Area Optimization) service uses:\n",
    "- **Fuzzy-TOPSIS**: Multi-criteria decision making for crop suitability\n",
    "- **Yield Prediction Model**: Predicts crop yield based on field conditions\n",
    "- **Price Prediction Model**: Forecasts market prices\n",
    "\n",
    "### 3.1 Fuzzy-TOPSIS Suitability Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy-TOPSIS Implementation\n",
    "class FuzzyTOPSIS:\n",
    "    \"\"\"\n",
    "    Fuzzy TOPSIS for multi-criteria crop suitability ranking.\n",
    "    \n",
    "    TOPSIS ranks alternatives by their distance to:\n",
    "    - Positive Ideal Solution (PIS): Best possible values\n",
    "    - Negative Ideal Solution (NIS): Worst possible values\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, criteria_weights=None):\n",
    "        self.default_weights = {\n",
    "            'soil_suitability': 0.25,\n",
    "            'water_coverage_ratio': 0.25,\n",
    "            'historical_yield': 0.20,\n",
    "            'water_sensitivity': 0.15,\n",
    "            'growth_duration': 0.15\n",
    "        }\n",
    "        self.weights = criteria_weights or self.default_weights\n",
    "    \n",
    "    def compute_scores(self, alternatives):\n",
    "        \"\"\"\n",
    "        Compute suitability scores for crop alternatives.\n",
    "        \n",
    "        Args:\n",
    "            alternatives: Dict of crop_id -> features dict\n",
    "        \n",
    "        Returns:\n",
    "            Dict of crop_id -> suitability score (0-1)\n",
    "        \"\"\"\n",
    "        scores = {}\n",
    "        for crop_id, features in alternatives.items():\n",
    "            score = self._compute_single_score(features)\n",
    "            scores[crop_id] = score\n",
    "        return scores\n",
    "    \n",
    "    def _compute_single_score(self, features):\n",
    "        \"\"\"Compute score for single crop using weighted criteria.\"\"\"\n",
    "        # Normalize features\n",
    "        soil_suit = features.get('soil_suitability', 0.5)\n",
    "        water_coverage = features.get('water_coverage_ratio', 0.5)\n",
    "        \n",
    "        # Historical yield normalized to max 10 t/ha\n",
    "        hist_yield = features.get('historical_yield_t_ha', 3.0)\n",
    "        hist_yield_norm = min(1.0, hist_yield / 10.0)\n",
    "        \n",
    "        # Water sensitivity (low=1.0, medium=0.6, high=0.3)\n",
    "        water_sens = features.get('water_sensitivity', 'medium')\n",
    "        water_sens_score = {'low': 1.0, 'medium': 0.6, 'high': 0.3}.get(water_sens, 0.6)\n",
    "        \n",
    "        # Growth duration (shorter is better, max 180 days)\n",
    "        duration = features.get('growth_duration_days', 120)\n",
    "        duration_score = max(0, 1 - (duration / 180))\n",
    "        \n",
    "        # Weighted sum\n",
    "        score = (\n",
    "            self.weights['soil_suitability'] * soil_suit +\n",
    "            self.weights['water_coverage_ratio'] * water_coverage +\n",
    "            self.weights['historical_yield'] * hist_yield_norm +\n",
    "            self.weights['water_sensitivity'] * water_sens_score +\n",
    "            self.weights['growth_duration'] * duration_score\n",
    "        )\n",
    "        \n",
    "        return round(max(0.0, min(1.0, score)), 3)\n",
    "\n",
    "# Example usage\n",
    "topsis = FuzzyTOPSIS()\n",
    "\n",
    "# Sample crop alternatives\n",
    "crops = {\n",
    "    'Rice': {\n",
    "        'soil_suitability': 0.9,\n",
    "        'water_coverage_ratio': 0.95,\n",
    "        'historical_yield_t_ha': 5.5,\n",
    "        'water_sensitivity': 'high',\n",
    "        'growth_duration_days': 120\n",
    "    },\n",
    "    'Maize': {\n",
    "        'soil_suitability': 0.85,\n",
    "        'water_coverage_ratio': 0.7,\n",
    "        'historical_yield_t_ha': 6.0,\n",
    "        'water_sensitivity': 'medium',\n",
    "        'growth_duration_days': 90\n",
    "    },\n",
    "    'Soybean': {\n",
    "        'soil_suitability': 0.75,\n",
    "        'water_coverage_ratio': 0.6,\n",
    "        'historical_yield_t_ha': 3.5,\n",
    "        'water_sensitivity': 'low',\n",
    "        'growth_duration_days': 100\n",
    "    },\n",
    "    'Vegetables': {\n",
    "        'soil_suitability': 0.8,\n",
    "        'water_coverage_ratio': 0.85,\n",
    "        'historical_yield_t_ha': 8.0,\n",
    "        'water_sensitivity': 'high',\n",
    "        'growth_duration_days': 60\n",
    "    }\n",
    "}\n",
    "\n",
    "scores = topsis.compute_scores(crops)\n",
    "ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Crop Suitability Ranking (Fuzzy-TOPSIS):\")\n",
    "print(\"-\" * 40)\n",
    "for rank, (crop, score) in enumerate(ranked, 1):\n",
    "    print(f\"{rank}. {crop}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab744fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize crop suitability comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of scores\n",
    "crop_names = [c[0] for c in ranked]\n",
    "crop_scores = [c[1] for c in ranked]\n",
    "colors = plt.cm.RdYlGn(np.array(crop_scores))\n",
    "\n",
    "axes[0].barh(crop_names, crop_scores, color=colors)\n",
    "axes[0].set_xlabel('Suitability Score')\n",
    "axes[0].set_title('Crop Suitability Scores')\n",
    "axes[0].set_xlim(0, 1)\n",
    "\n",
    "# Radar chart of criteria\n",
    "categories = ['Soil', 'Water', 'Yield', 'W.Sensitivity', 'Duration']\n",
    "N = len(categories)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "ax = axes[1]\n",
    "ax = plt.subplot(122, polar=True)\n",
    "\n",
    "for crop_name, features in list(crops.items())[:3]:  # Top 3 crops\n",
    "    values = [\n",
    "        features['soil_suitability'],\n",
    "        features['water_coverage_ratio'],\n",
    "        min(1.0, features['historical_yield_t_ha'] / 10),\n",
    "        {'low': 1.0, 'medium': 0.6, 'high': 0.3}[features['water_sensitivity']],\n",
    "        max(0, 1 - features['growth_duration_days'] / 180)\n",
    "    ]\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=2, label=crop_name)\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_title('Crop Criteria Comparison')\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebcde8",
   "metadata": {},
   "source": [
    "### 3.2 Yield Prediction Model\n",
    "\n",
    "The yield prediction model estimates crop yield based on:\n",
    "- Soil characteristics (pH, EC, texture)\n",
    "- Water availability\n",
    "- Climate conditions\n",
    "- Historical performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32af0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network for Yield Prediction\n",
    "class YieldPredictionMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron for crop yield prediction.\n",
    "    \n",
    "    Input features:\n",
    "    - soil_suitability: Soil match score (0-1)\n",
    "    - water_coverage_ratio: Water availability ratio (0-1)\n",
    "    - soil_ph: Soil pH value (4-9)\n",
    "    - soil_ec: Electrical conductivity (mS/cm)\n",
    "    - season_avg_temp: Average temperature (°C)\n",
    "    - season_rainfall_mm: Total rainfall (mm)\n",
    "    - growth_duration_days: Crop growth period\n",
    "    \n",
    "    Output:\n",
    "    - Predicted yield (tonnes/hectare)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=7, hidden_sizes=[64, 32, 16]):\n",
    "        super(YieldPredictionMLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        layers.append(nn.ReLU())  # Yield must be positive\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Create model\n",
    "yield_model = YieldPredictionMLP()\n",
    "print(yield_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in yield_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d96fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic yield data for demonstration\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate features\n",
    "yield_data = pd.DataFrame({\n",
    "    'soil_suitability': np.random.uniform(0.3, 1.0, n_samples),\n",
    "    'water_coverage_ratio': np.random.uniform(0.4, 1.0, n_samples),\n",
    "    'soil_ph': np.random.uniform(5.0, 8.0, n_samples),\n",
    "    'soil_ec': np.random.uniform(0.5, 2.5, n_samples),\n",
    "    'season_avg_temp': np.random.uniform(20, 35, n_samples),\n",
    "    'season_rainfall_mm': np.random.uniform(100, 500, n_samples),\n",
    "    'growth_duration_days': np.random.uniform(60, 150, n_samples)\n",
    "})\n",
    "\n",
    "# Generate target (yield) with realistic relationship\n",
    "yield_data['yield_t_ha'] = (\n",
    "    3.0 +\n",
    "    yield_data['soil_suitability'] * 4 +\n",
    "    yield_data['water_coverage_ratio'] * 3 +\n",
    "    (yield_data['soil_ph'] - 6.5).abs() * -0.5 +  # pH closer to neutral is better\n",
    "    yield_data['season_rainfall_mm'] / 200 +\n",
    "    np.random.normal(0, 0.5, n_samples)  # Random noise\n",
    ").clip(0.5, 12.0)  # Realistic yield range\n",
    "\n",
    "print(yield_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize yield data correlations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "features_to_plot = ['soil_suitability', 'water_coverage_ratio', 'soil_ph', \n",
    "                    'season_rainfall_mm', 'season_avg_temp', 'growth_duration_days']\n",
    "\n",
    "for ax, feature in zip(axes.flatten(), features_to_plot):\n",
    "    ax.scatter(yield_data[feature], yield_data['yield_t_ha'], alpha=0.5, s=10)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Yield (t/ha)')\n",
    "    ax.set_title(f'Yield vs {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636311e7",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation Metrics\n",
    "\n",
    "Key metrics for evaluating the models:\n",
    "- **RMSE** (Root Mean Square Error): Penalizes large errors\n",
    "- **MAE** (Mean Absolute Error): Average absolute difference\n",
    "- **MAPE** (Mean Absolute Percentage Error): Percentage-based error\n",
    "- **R²** (Coefficient of Determination): Explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecffd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Calculate and display model evaluation metrics.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"RMSE:  {rmse:.4f}\")\n",
    "    print(f\"MAE:   {mae:.4f}\")\n",
    "    print(f\"MAPE:  {mape:.2f}%\")\n",
    "    print(f\"R²:    {r2:.4f}\")\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'mape': mape, 'r2': r2}\n",
    "\n",
    "# Example evaluation (using our LSTM predictions)\n",
    "evaluate_model(y_test, predictions.flatten(), \"Water Level LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77dc2be",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "To further develop the ML models:\n",
    "\n",
    "1. **Data Collection**\n",
    "   - Gather real sensor data from irrigation systems\n",
    "   - Collect historical yield data from farms\n",
    "   - Integrate satellite imagery for crop health\n",
    "\n",
    "2. **Model Improvements**\n",
    "   - Implement attention mechanisms for LSTM\n",
    "   - Use ensemble methods for yield prediction\n",
    "   - Add uncertainty quantification\n",
    "\n",
    "3. **Production Deployment**\n",
    "   - Export models using TorchScript or ONNX\n",
    "   - Set up MLflow for experiment tracking\n",
    "   - Create model versioning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc78b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint example\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the trained LSTM model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'input_size': 3,\n",
    "        'hidden_size': 64,\n",
    "        'num_layers': 2,\n",
    "        'output_size': 1\n",
    "    },\n",
    "    'scaler': scaler,\n",
    "    'training_info': {\n",
    "        'epochs': 50,\n",
    "        'final_train_loss': train_losses[-1],\n",
    "        'final_val_loss': val_losses[-1]\n",
    "    }\n",
    "}, '../models/water_level_lstm.pth')\n",
    "\n",
    "print(\"Model saved to ../models/water_level_lstm.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
